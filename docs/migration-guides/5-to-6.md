# Upgrading from 5.X to 6.X

The CLI hasn't changed at all.

## Split in several modules for cleaner importing

To better separate pure javascript code from code relying on Node.js core libraries, json2csv has been split in several independent packages that must be added separately.

```js
const {
  Parser,
  StreamParser,
  NodeTransform,
  NodeAsyncParser,
  WhatwgTransformStream,
  WhatwgAsyncParser,
  transforms: { flatten, unwind },
  formatters: { number: numberFormatter, string: stringFormatter, stringExcel: stringExcelFormatter, stringQuoteOnlyIfNecessary: stringQuoteOnlyIfNecessaryFormatter },
} = require('json2csv');
```

should be replaced by

```js
const { Parser, StreamParser } = require('@json2csv/plainjs');
const { Transform, AsyncParser } = require('@json2csv/node');
const { TransformStream, AsyncParser } = require('@json2csv/whatwg');
const { flatten, unwind } = require('@json2csv/transforms');
const { number: numberFormatter, string: stringFormatter, stringExcel: stringExcelFormatter, stringQuoteOnlyIfNecessary: stringQuoteOnlyIfNecessaryFormatter } = require('@json2csv/formatters');
```

## Convenience methods parse and parseAsync have been removed.
These 2 methods are equivalent to:

```js
const parse = (data, opts) => new Parser(opts).parse(data);

const parseAsync = (data, opts, transformOpts) => new NodeAsyncParser(opts, transformOpts).parse(data).promise();
```

## AsyncParser changes

Async parser have been simplified to be a class with a single `parse` method which replaces the previous `fromInput` method. `throughTransform` and `toOutput` can be replaced by Node's standard [pipe](https://nodejs.org/api/stream.html#stream_readable_pipe_destination_options) method or the newer [pipeline](https://nodejs.org/api/stream.html#stream_stream_pipeline_source_transforms_destination_callback) utility.

What used to be
```js
const { AsyncParser } = require('json2csv');
const json2csvParser = new AsyncParser();
const csv = await json2csvParser.fromInput(myData).throughTransform(myTransform).toOutput(myOutput);
```

should be replaced by

```js
import { AsyncParser } from '@json2csv/node');
const json2csvParser = new AsyncParser();
json2csvParser.parse(myData.pipe(myTransform)).pipe(myOutput);
```

The `promise` method has been kept but it doesn't take any argument as it used to. Now it always keeps the whole CSV and returns it.


What used to be
```js
const { AsyncParser } = require('json2csv');
const json2csvParser = new AsyncParser();
const csv = await json2csvParser.fromInput(myData).promise();
```

should be replaced by

```js
import { AsyncParser } from '@json2csv/node');
const json2csvParser = new AsyncParser();
const csv = await json2csvParser.parse(myData).promise();
```

If you want to wait for the stream to finish but not keep the CSV in memory you can use the [stream.finished](https://nodejs.org/api/stream.html#stream_stream_finished_stream_options_callback) utility from Node's stream module.

Finally, the `input`, `transform` and `processor` properties have been remove.
`input` is just your data stream.
`transform` and `processor` are equivalent to the return of the `parse` method.

Before you could instantiate an `AsyncParser` and push data into it. Now you can simply pass the data as the argument to the `parse` method if you have the entire dataset or you can manually create an array and push data to it.

What used to be

```js
asyncParser.processor
  .on('data', (chunk) => (csv += chunk.toString()))
  .on('end', () => console.log(csv))
  .on('error', (err) => console.error(err));

myData.forEach(item => asyncParser.input.push(item));
asyncParser.input.push(null); // Sending `null` to a stream signal that no more data is expected and ends it.
```

now can be done as

```js
asyncParser.parse(myData)
  .on('data', (chunk) => (csv += chunk.toString()))
  .on('end', () => console.log(csv))
  .on('error', (err) => console.error(err));
```

or done manually as

```js
import { Readable } from 'stream';

const myManualInput = new Readable({ objectMode: true });
myManualInput._read = () => {};

asyncParser.parse(myManualInput)
  .on('data', (chunk) => (csv += chunk.toString()))
  .on('end', () => console.log(csv))
  .on('error', (err) => console.error(err));

myData.forEach(item => myManualInput.push(item)); // This is useful when the data is coming asynchronously from a request or ws for example.
myManualInput.push(null);
```

## Formatters have been added and string formatting options removed

In the JavaScript modules, `formatters` are introduced and the `quote`, `escapedQuote` and `excelStrings` options are removed.

Custom `quote` and `escapedQuote` are applied by setting the properties in the `string` formatter.

```js
const { Parser } = require('json2csv');
const json2csvParser = new Parser({ quote: "'", escapedQuote: "\\'" });
const csv = json2csvParser.parse(myData);
```

should be replaced by

```js
import { Parser } from '@json2csv/plainjs';
import { string as stringFormatter } from '@json2csv/formatters';
const json2csvParser = new Parser({
  formatters: {
    string: stringFormatter({ quote: '\'', escapedQuote: '\\\'' })),
  }
});
const csv = json2csvParser.parse(myData);
```

`excelStrings` can be used by using the `stringExcel` formatter.

```js
const { Parser } = require('json2csv');
const json2csvParser = new Parser({
  quote: "'",
  escapedQuote: "\\'",
  excelStrings: true,
});
const csv = json2csvParser.parse(myData);
```

should be replaced by

```js
const { stringExcel: stringExcelFormatter } = require('json2csv/formatters');
const Parser = require('json2csv/Parser');
const json2csvParser = new Parser({
  formatters: {
    string: stringExcelFormatter,
  }
});
const csv = json2csvParser.parse(myData);
```
